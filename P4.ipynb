{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "P4.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTxJ13XOxb4Q",
        "outputId": "0483236a-d883-433a-ccc9-790c876e89ef"
      },
      "source": [
        "import os\n",
        "print(os.getcwd())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YKWIyQuOeE6"
      },
      "source": [
        "# Encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfX0MOilQK7i"
      },
      "source": [
        "Ya que en el dataset que se nos dio tenian vairiables que en su mayoria son ordinales, el encoding se hizo de manera que se les dio un valor entero a cada uno. Variables que no tienen una ordinalidad estricta como por ejemplo raza se han evaluado en base a que tan comunes son, por ejemplo en este dataset Otro es el mas raro,y por lo tanto el que tiene mayor valor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I56O4TccOi3x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "outputId": "7daf1f2d-e531-4425-8917-89c3c791e597"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "\n",
        "df = pd.read_csv('drive/MyDrive/Archivos_collab/adultIncome.csv')\n",
        "df.replace(inplace=True, to_replace=[' Never-worked'],value= 0)\n",
        "df.replace(inplace=True, to_replace=[' Private'],value= 0)\n",
        "df.replace(inplace=True, to_replace=[' Local-gov'], value=1)\n",
        "df.replace(inplace=True, to_replace=[' Federal-gov'], value=2)\n",
        "df.replace(inplace=True, to_replace=[' Preschool'], value=-1)\n",
        "df.replace(inplace=True, to_replace=[' HS-grad'], value=0)\n",
        "df.replace(inplace=True, to_replace=[' Some-college'], value=1)\n",
        "df.replace(inplace=True, to_replace=[' Bachelors'], value=2)\n",
        "df.replace(inplace=True, to_replace=[' Prof-school'], value=3)\n",
        "df.replace(inplace=True, to_replace=[' Masters'], value=4)\n",
        "df.replace(inplace=True, to_replace=[' Doctorate'],value= 5)\n",
        "df.replace(inplace=True, to_replace=[' Never-married'], value=0)\n",
        "df.replace(inplace=True, to_replace=['Married'], value=1)\n",
        "df.replace(inplace=True, to_replace=[' Divorced'], value=2 )\n",
        "df.replace(inplace=True, to_replace=[' Widowed'], value=3) \n",
        "df.replace(inplace=True, to_replace=[' Black'], value=0)\n",
        "df.replace(inplace=True, to_replace=[' Asian-Pac-Islander'], value=2)\n",
        "df.replace(inplace=True, to_replace=[' Amer-Indian-Eskimo'], value=3)\n",
        "df.replace(inplace=True, to_replace=[' Other'], value=4)\n",
        "df.replace(inplace=True, to_replace=[' White'], value=1)\n",
        "df.replace(inplace=True, to_replace=[' Male'], value=0)\n",
        "df.replace(inplace=True, to_replace=[' Female'],value= 1)\n",
        "df.replace(inplace=True, to_replace=[' <=50K'], value=0)\n",
        "df.replace(inplace=True, to_replace=[' >50K'], value=1)\n",
        "df.to_csv('incomeProcessed.csv', index=False)\n",
        "df = pd.read_csv('incomeProcessed.csv')\n",
        "print(df.head())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-e2d5fea523c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'drive/MyDrive/Archivos_collab/adultIncome.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_replace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m' Never-worked'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_replace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m' Private'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'drive/MyDrive/Archivos_collab/adultIncome.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5jTO4cKxav8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wltxKkhLUnJG"
      },
      "source": [
        "# Discretizacion y normalizacion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Wors4FRU0qZ"
      },
      "source": [
        "Ya que tenemos variables como edad y horas por semana trabajadas, con desviaciones estandar mas altas que el resto de nuestras otras variables, queremos normalizarlas para que existan en el mismo rango de valores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "O802Y2DiUwbs",
        "outputId": "0afdfe56-6a54-4fdc-ab80-f7ef7685a2d5"
      },
      "source": [
        "df=(df-df.min())/(df.max()-df.min())\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>wc</th>\n",
              "      <th>education</th>\n",
              "      <th>marital status</th>\n",
              "      <th>race</th>\n",
              "      <th>gender</th>\n",
              "      <th>hours per week</th>\n",
              "      <th>IncomeClass</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.287671</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.397959</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.150685</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.397959</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.273973</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.25</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.397959</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.191781</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.25</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.342466</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.397959</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        age   wc  education  ...  gender  hours per week  IncomeClass\n",
              "0  0.287671  0.0   0.166667  ...     0.0        0.397959          0.0\n",
              "1  0.150685  0.0   0.500000  ...     1.0        0.397959          0.0\n",
              "2  0.273973  0.0   0.833333  ...     1.0        0.397959          0.0\n",
              "3  0.191781  0.0   0.833333  ...     1.0        0.500000          1.0\n",
              "4  0.342466  0.0   0.500000  ...     0.0        0.397959          1.0\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_btdIFvgq-3"
      },
      "source": [
        "# K-means"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXim2Aqtg1-S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "421eb13b-d1ed-43a6-890d-79a412622daa"
      },
      "source": [
        "import math\n",
        "import collections\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import scatter\n",
        "import pandas as pd\n",
        "# observaciones tiene la forma de ((x1,y1,z1),(x2,y2,z2))\n",
        "\n",
        "# findCentroid es una funcion que encuentra el hipotetico centroide de un set de observaciones, encontrando su promedio\n",
        "\n",
        "\n",
        "def findCentroid(observaciones):\n",
        "    n_dimensiones = len(observaciones[0])\n",
        "    centroide = []\n",
        "    for dimension in range(n_dimensiones):\n",
        "        centroide.append(0)\n",
        "        for obs in observaciones:\n",
        "            current = obs[dimension]\n",
        "            centroide[dimension] = centroide[dimension] + current\n",
        "\n",
        "        centroide[dimension] = centroide[dimension]/len(observaciones)\n",
        "    return centroide\n",
        "\n",
        "\n",
        "def euclidDistance(coord_list_a, coord_list_b):\n",
        "    accum = 0\n",
        "    dimensions = len(coord_list_a)\n",
        "    for dimension in range(dimensions):\n",
        "        line = (coord_list_a[dimension] - coord_list_b[dimension]) * \\\n",
        "            (coord_list_a[dimension] - coord_list_b[dimension])\n",
        "        accum += line\n",
        "    root = math.sqrt(accum)\n",
        "    return root\n",
        "\n",
        "# findNearestMean itera sobre las medias y retorna la que este mas cercana por distancia eculideana\n",
        "\n",
        "\n",
        "def findNearestMean(observacion, means):\n",
        "    min_distance = 999999\n",
        "    n_mean = []\n",
        "    for mean in means:\n",
        "        distancia = euclidDistance(observacion, mean)\n",
        "        if distancia < min_distance:\n",
        "            n_mean = mean\n",
        "            min_distance = distancia\n",
        "    return n_mean\n",
        "\n",
        "# se retorna un diccionario con las medias como llaves, y la lista de observaciones que la tienen como mas cercana como value\n",
        "\n",
        "\n",
        "def findAllNearestMeans(observaciones, means):\n",
        "    observaciones_per_mean = collections.defaultdict(list)\n",
        "    for observacion in observaciones:\n",
        "        key = findNearestMean(observacion, means)\n",
        "        buffer = observaciones_per_mean[tuple(key)]\n",
        "        buffer.append(observacion)\n",
        "    return observaciones_per_mean\n",
        "\n",
        "# RandomK es un procedimiento simple que elije un sample aleatorio de los que se tienen; y los inicializa como means.\n",
        "\n",
        "\n",
        "def generateRandomK(k, observaciones):\n",
        "    medias = random.sample(observaciones, k)\n",
        "    return medias\n",
        "\n",
        "\n",
        "def plotMeans2d(dict_medias):\n",
        "    dimensiones = [[], [], []]\n",
        "    media_colors = {}\n",
        "    unique_medias = list(set(dict_medias.keys()))\n",
        "    step_size = (256**3)//len(unique_medias)\n",
        "    for i, m in enumerate(unique_medias):\n",
        "        media_colors[m] = '#{}'.format(hex(step_size*i)[2:])\n",
        "    for media in dict_medias:\n",
        "        for observacion in dict_medias[media]:\n",
        "            dimensiones[2].append(tuple(media))\n",
        "            for dimension in range(len(observacion)):\n",
        "                dimensiones[dimension].append(observacion[dimension])\n",
        "    print('el pepe')\n",
        "    print(dimensiones[2])\n",
        "    colors = [media_colors[current_media] for current_media in dimensiones[2]]\n",
        "    for item in range(len(colors)):\n",
        "        if colors[item] == '#0':\n",
        "            colors[item] = '#000000'\n",
        "    #tr = plt.scatter(dimensiones[0], dimensiones[1],  alpha=0.5)\n",
        "    tr = plt.scatter(dimensiones[0], dimensiones[1], c=colors, alpha=0.5)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def kmeans(k, observaciones):\n",
        "    # encontramos la configuracion inicial\n",
        "    medias = generateRandomK(k, observaciones)\n",
        "    cercanas = findAllNearestMeans(observaciones, medias)\n",
        "    # se sigue iterando hasta que se deje de cambiar la media despues de una iteracion\n",
        "    while True:\n",
        "        # cada loop se usa la lista de centroides para ver las medias updateadas\n",
        "        centroides = []\n",
        "        \n",
        "        for media in medias:\n",
        "            # para cada cluster, se encuentra su centroide\n",
        "            \n",
        "            c = cercanas[tuple(media)]\n",
        "            centroides.append(findCentroid(c))\n",
        "        if medias == centroides:\n",
        "            break\n",
        "        medias = centroides\n",
        "        cercanas = findAllNearestMeans(observaciones, medias)\n",
        "    return medias\n",
        "\n",
        "\n",
        "def dfToList(df):\n",
        "    lista = []\n",
        "    for row in df.itertuples():\n",
        "        lista.append(list(row)[1:])\n",
        "    return lista\n",
        "\n",
        "mapa = dfToList(df)\n",
        "result = kmeans(4, mapa)\n",
        "print (result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.25112790008948255, 0.06606485740570377, 0.29410073597055963, 0.2356255749769893, 0.24899379024839005, 0.0, 0.4088778795786538, 0.0], [0.362963930673238, 0.11137602179836512, 0.44883439297608024, 0.3339388434756177, 0.25039736603088103, 0.0, 0.46000157556210997, 1.0], [0.1648638203832361, 0.061490002738975626, 0.3309139048662465, 0.04720167990504899, 0.23520953163516845, 1.0, 0.3566174210029201, 0.001369487811558477], [0.3832548233977678, 0.12779973649538867, 0.3482652613087393, 0.6181379007466066, 0.23641304347826086, 1.0, 0.38882390901025365, 0.2644927536231884]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLI05e3vgnDb"
      },
      "source": [
        "# KNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7LBZH09gvMN"
      },
      "source": [
        "# Supervisado y comparaciones\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMLynnQRg0UQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}